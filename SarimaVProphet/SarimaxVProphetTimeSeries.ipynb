{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71478bba-4e97-4d12-b294-e3805acfa266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x1280 with 0 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x1280 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Imports\n",
    "import time\n",
    "import webbrowser\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'g'\n",
    "\n",
    "import time_series_functions as tsf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "plt.figure(figsize=(8, 16), dpi=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89fb626-28c3-42d7-afa5-a553e5152122",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_df=pd.read_csv('monthly_energy_consumption.csv',\n",
    "                      index_col=[0],parse_dates=True)\n",
    "monthly_df.head()\n",
    "train=monthly_df.loc['2006':'2016'].copy()\n",
    "test=monthly_df.loc['2017':'2018'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c002e42-e233-404c-a498-938f099f9ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize oob\n",
      " ARIMA(1,0,1)(1,0,1)[12] intercept   : OOB=653431849856.862, Time=0.24 sec\n",
      " ARIMA(0,0,0)(0,0,0)[12] intercept   : OOB=1502548724718.127, Time=0.01 sec\n",
      " ARIMA(1,0,0)(1,0,0)[12] intercept   : OOB=771586111881.493, Time=0.11 sec\n",
      " ARIMA(0,0,1)(0,0,1)[12] intercept   : OOB=869349721333.883, Time=0.04 sec\n",
      " ARIMA(0,0,0)(0,0,0)[12]             : OOB=118240047904646.500, Time=0.01 sec\n",
      " ARIMA(1,0,1)(0,0,1)[12] intercept   : OOB=879258221192.807, Time=0.06 sec\n",
      " ARIMA(1,0,1)(1,0,0)[12] intercept   : OOB=635299256615.025, Time=0.16 sec\n",
      " ARIMA(1,0,1)(0,0,0)[12] intercept   : OOB=1550744031074.902, Time=0.03 sec\n",
      " ARIMA(1,0,1)(2,0,0)[12] intercept   : OOB=632855771898.360, Time=0.48 sec\n",
      " ARIMA(1,0,1)(2,0,1)[12] intercept   : OOB=562511610480.988, Time=0.56 sec\n",
      " ARIMA(1,0,1)(2,0,2)[12] intercept   : OOB=593390149649.930, Time=0.67 sec\n",
      " ARIMA(1,0,1)(1,0,2)[12] intercept   : OOB=623911196038.341, Time=0.57 sec\n",
      " ARIMA(0,0,1)(2,0,1)[12] intercept   : OOB=inf, Time=0.49 sec\n",
      " ARIMA(1,0,0)(2,0,1)[12] intercept   : OOB=inf, Time=0.53 sec\n",
      " ARIMA(2,0,1)(2,0,1)[12] intercept   : OOB=596869336914.626, Time=0.64 sec\n",
      " ARIMA(1,0,2)(2,0,1)[12] intercept   : OOB=511809439503.874, Time=0.48 sec\n",
      " ARIMA(1,0,2)(1,0,1)[12] intercept   : OOB=565700605139.989, Time=0.28 sec\n",
      " ARIMA(1,0,2)(2,0,0)[12] intercept   : OOB=551014965950.854, Time=0.39 sec\n",
      " ARIMA(1,0,2)(2,0,2)[12] intercept   : OOB=490749987153.196, Time=0.80 sec\n",
      " ARIMA(1,0,2)(1,0,2)[12] intercept   : OOB=583049757884.714, Time=0.72 sec\n",
      " ARIMA(0,0,2)(2,0,2)[12] intercept   : OOB=1246643000988.378, Time=0.77 sec\n",
      " ARIMA(2,0,2)(2,0,2)[12] intercept   : OOB=481069988013.007, Time=0.91 sec\n",
      " ARIMA(2,0,2)(1,0,2)[12] intercept   : OOB=527413947438.392, Time=0.84 sec\n",
      " ARIMA(2,0,2)(2,0,1)[12] intercept   : OOB=513283098338.706, Time=0.73 sec\n",
      " ARIMA(2,0,2)(1,0,1)[12] intercept   : OOB=560641666920.187, Time=0.33 sec\n",
      " ARIMA(2,0,1)(2,0,2)[12] intercept   : OOB=inf, Time=0.74 sec\n",
      " ARIMA(3,0,2)(2,0,2)[12] intercept   : OOB=466118224635.399, Time=1.06 sec\n",
      " ARIMA(3,0,2)(1,0,2)[12] intercept   : OOB=479078165847.799, Time=0.78 sec\n",
      " ARIMA(3,0,2)(2,0,1)[12] intercept   : OOB=444023925931.947, Time=0.82 sec\n",
      " ARIMA(3,0,2)(1,0,1)[12] intercept   : OOB=533952390509.019, Time=0.34 sec\n",
      " ARIMA(3,0,2)(2,0,0)[12] intercept   : OOB=518137261096.089, Time=0.76 sec\n",
      " ARIMA(3,0,2)(1,0,0)[12] intercept   : OOB=494463512323.222, Time=0.29 sec\n",
      " ARIMA(3,0,1)(2,0,1)[12] intercept   : OOB=662293561446.566, Time=0.86 sec\n",
      " ARIMA(4,0,2)(2,0,1)[12] intercept   : OOB=439192492794.719, Time=0.83 sec\n",
      " ARIMA(4,0,2)(1,0,1)[12] intercept   : OOB=468744157817.315, Time=0.35 sec\n",
      " ARIMA(4,0,2)(2,0,0)[12] intercept   : OOB=inf, Time=0.76 sec\n",
      " ARIMA(4,0,2)(2,0,2)[12] intercept   : OOB=506301507906.457, Time=0.92 sec\n",
      " ARIMA(4,0,2)(1,0,0)[12] intercept   : OOB=416841079731.457, Time=0.31 sec\n",
      " ARIMA(4,0,2)(0,0,0)[12] intercept   : OOB=269824142346.425, Time=0.14 sec\n",
      " ARIMA(4,0,2)(0,0,1)[12] intercept   : OOB=227481857273.501, Time=0.30 sec\n",
      " ARIMA(4,0,2)(0,0,2)[12] intercept   : OOB=183457157566.452, Time=0.73 sec\n",
      " ARIMA(4,0,2)(1,0,2)[12] intercept   : OOB=448486112458.941, Time=0.90 sec\n",
      " ARIMA(3,0,2)(0,0,2)[12] intercept   : OOB=inf, Time=0.66 sec\n",
      " ARIMA(4,0,1)(0,0,2)[12] intercept   : OOB=713020628746.150, Time=0.47 sec\n",
      " ARIMA(5,0,2)(0,0,2)[12] intercept   : OOB=233486052901.248, Time=0.81 sec\n",
      " ARIMA(4,0,3)(0,0,2)[12] intercept   : OOB=222806629391.572, Time=0.78 sec\n",
      " ARIMA(3,0,1)(0,0,2)[12] intercept   : OOB=786412388945.774, Time=0.44 sec\n",
      " ARIMA(3,0,3)(0,0,2)[12] intercept   : OOB=inf, Time=0.76 sec\n",
      " ARIMA(5,0,1)(0,0,2)[12] intercept   : OOB=515661404230.369, Time=0.37 sec\n",
      " ARIMA(5,0,3)(0,0,2)[12] intercept   : OOB=175915673469.800, Time=0.78 sec\n",
      " ARIMA(5,0,3)(0,0,1)[12] intercept   : OOB=196573299791.710, Time=0.35 sec\n",
      " ARIMA(5,0,3)(1,0,2)[12] intercept   : OOB=414717835797.315, Time=0.97 sec\n",
      " ARIMA(5,0,3)(1,0,1)[12] intercept   : OOB=418159674918.719, Time=0.44 sec\n",
      " ARIMA(5,0,4)(0,0,2)[12] intercept   : OOB=167569725685.346, Time=0.97 sec\n",
      " ARIMA(5,0,4)(0,0,1)[12] intercept   : OOB=169937755749.295, Time=0.44 sec\n",
      " ARIMA(5,0,4)(1,0,2)[12] intercept   : OOB=inf, Time=1.22 sec\n",
      " ARIMA(5,0,4)(1,0,1)[12] intercept   : OOB=inf, Time=0.48 sec\n",
      " ARIMA(4,0,4)(0,0,2)[12] intercept   : OOB=inf, Time=0.97 sec\n",
      " ARIMA(5,0,5)(0,0,2)[12] intercept   : OOB=190139181253.126, Time=1.17 sec\n",
      " ARIMA(4,0,5)(0,0,2)[12] intercept   : OOB=197060298028.546, Time=1.12 sec\n",
      " ARIMA(5,0,4)(0,0,2)[12]             : OOB=956012279723.989, Time=0.96 sec\n",
      "\n",
      "Best model:  ARIMA(5,0,4)(0,0,2)[12] intercept\n",
      "Total fit time: 35.932 seconds\n"
     ]
    }
   ],
   "source": [
    "import pmdarima as pmd\n",
    "\n",
    "model=pmd.auto_arima(train.energy,start_p=1,start_q=1,test='adf',m=12,\n",
    "                     seasonal=True,trace=True,random_state=2024,\n",
    "                     information_criterion='oob',out_of_sample_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229d195d-65e8-47bd-8b33-9ad51d2537d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'VALID_CRITERIA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pmd\u001b[38;5;241m.\u001b[39marima\u001b[38;5;241m.\u001b[39mauto_arima\u001b[38;5;241m.\u001b[39mVALID_CRITERIA\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'VALID_CRITERIA'"
     ]
    }
   ],
   "source": [
    "pmd.arima.auto_arima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a656943-43a8-4c2a-a313-f56dd9829ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 10.292841\n",
      "         Iterations: 50\n",
      "         Function evaluations: 88\n",
      "         Gradient evaluations: 88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7314415202830926"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "sarima=SARIMAX(train.energy.to_period(\"M\"), \n",
    "            order=(2,1,3),\n",
    "              seasonal_order=(4,0,1,12),\n",
    "           enforce_stationarity=False,\n",
    "           enforce_invertibility=False).fit(method='cg')\n",
    "preds=sarima.predict(start=test.index[0],\n",
    "                      end=test.index[-1]).values\n",
    "(mean_squared_error(test,preds))**(1/2)/1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66d832-5771-47b5-bcae-ea0315a37783",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Functions        \n",
    "def sarimax_gridsearch(ts, pdq, pdqs, maxiter=200, freq='M'):\n",
    "    '''\n",
    "    Input: \n",
    "        ts : your time series data\n",
    "        pdq : ARIMA combinations from above\n",
    "        pdqs : seasonal ARIMA combinations from above\n",
    "        maxiter : number of iterations, increase if your model isn't converging\n",
    "        frequency : default='M' for month. Change to suit your time series frequency\n",
    "            e.g. 'D' for day, 'H' for hour, 'Y' for year. \n",
    "        \n",
    "    Return:\n",
    "        Prints out top 5 parameter combinations\n",
    "        Returns dataframe of parameter combinations ranked by BIC\n",
    "    '''\n",
    "\n",
    "    # Run a grid search with pdq and seasonal pdq parameters and get the best BIC value\n",
    "    ans = []\n",
    "    count=0\n",
    "    for comb in pdq:\n",
    "        for combs in pdqs:\n",
    "            try:\n",
    "                count+=1\n",
    "                mod = sm.tsa.statespace.SARIMAX(ts, # this is your time series you will input\n",
    "                                                order=comb,\n",
    "                                                seasonal_order=combs,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False,\n",
    "                                                freq=freq)\n",
    "\n",
    "                output = mod.fit(disp=False,maxiter=maxiter,method_kwargs={\"warn_convergence\": False}) \n",
    "                ans.append([comb, combs, output.bic])\n",
    "                #print('SARIMAX {} x {} : BIC Calculated ={}'.format(comb, combs, output.bic))\n",
    "                if count%300==0:\n",
    "                    print(count)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    # Find the parameters with minimal BIC value\n",
    "\n",
    "    # Convert into dataframe\n",
    "    ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'bic'])\n",
    "    ans_df=ans_df[~ans_df.duplicated(keep='first')]\n",
    "\n",
    "    # Sort and return top 5 combinations\n",
    "    ans_df = ans_df.sort_values(by=['bic'],ascending=True)[0:5]\n",
    "    ans_df=ans_df.reset_index(drop=True)\n",
    "    \n",
    "    return ans_df\n",
    "\n",
    "def calculate_adfuller(time_series):\n",
    "    result = adfuller(time_series.dropna(),autolag='AIC')\n",
    "    return result[1]\n",
    "\n",
    "def calculate_d(train):\n",
    "    \n",
    "    d=0\n",
    "    p_value=1\n",
    "    while d<4:\n",
    "    \n",
    "    \n",
    "        p_value=tsf.calculate_adfuller(train)\n",
    "        if p_value<=0.05:\n",
    "            return d\n",
    "        else:\n",
    "            d+=1\n",
    "            train=train.diff()\n",
    "    return d\n",
    "def calculate_p_q(time_series,d,D,freq):\n",
    "    \n",
    "    p=q=range(0,3)\n",
    "    to_perm=list(p)+list(q)\n",
    "    permutations=[list(x) for x in itertools.permutations(to_perm,2)]\n",
    "    pdq=[x.insert(1,d) or x for x in permutations]\n",
    "    pdq=[tuple(x) for x in pdq]\n",
    "    seasonal_pdq = [(x[0], D, x[2], seasonality) for x in pdq]\n",
    "    ##Determining best parameters\n",
    "    outcome=sarimax_gridsearch(time_series, pdq, seasonal_pdq,freq=freq)\n",
    "    \n",
    "    return outcome\n",
    "\n",
    "def pickle_model(pdq,pdqs, model, period):\n",
    "    \n",
    "    file = open('best_parameters.pkl', 'rb')\n",
    "    best_parameters = pickle.load(file)\n",
    "    file.close()\n",
    "    best_parameters[period]=[(pdq),(pdqs),model]\n",
    "    # open a file, where you ant to store the data\n",
    "    file = open('best_parameters.pkl', 'wb')\n",
    "\n",
    "    # dump information to that file\n",
    "    pickle.dump(best_parameters, file)\n",
    "\n",
    "    print('Pickled!!!')\n",
    "\n",
    "def printing_ci():\n",
    "\n",
    "    fig=ts_test.plot(label='Observed',alpha=0.7,figsize=(14,10))\n",
    "    #ts_test.plot(figsize=(16,8))\n",
    "    fig.set_xlabel(period)\n",
    "    fig.set_ylabel('Energy Consumption')\n",
    "    fig.fill_between(ci.index,\n",
    "                    ci.iloc[:,0],\n",
    "                    ci.iloc[:,1],color='k',alpha=.2)\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4be999-1d2e-4696-a6a0-89e4af6dd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading gthe datset and cleaning dups\n",
    "df=pd.read_csv('AEP_hourly.csv')\n",
    "#print(df.dtypes,df.shape)\n",
    "df=df.groupby('Datetime').AEP_MW.mean()\n",
    "df=df.reset_index()\n",
    "\n",
    "#creating the time series\n",
    "df['Datetime']=pd.to_datetime(df['Datetime'])\n",
    "new_df=df.set_index(['Datetime'])\n",
    "\n",
    "new_df.sort_index(inplace=True)\n",
    "##Creating full calendar\n",
    "start=new_df.index[0]\n",
    "end=new_df.index[-1]\n",
    "full_calendar=pd.date_range(start, end,freq='H')\n",
    "##Putting it all together\n",
    "calendar=pd.DataFrame(full_calendar,columns=['Datetime']).set_index('Datetime')#,new_df.head()\n",
    "final_df=calendar.join(new_df)\n",
    "print(final_df.isnull().sum())\n",
    "final_df=final_df.interpolate()\n",
    "final_df.head()\n",
    "print(final_df.isnull().sum())\n",
    "hourly_df=final_df[['AEP_MW']].asfreq('H').copy()\n",
    "daily_df=final_df[['AEP_MW']].resample('D').sum()[:-1]\n",
    "weekly_df=final_df[['AEP_MW']].resample('W').sum()[1:-1]\n",
    "monthly_df=final_df[['AEP_MW']].resample('M').sum()[3:-1]\n",
    "quarterly_df=final_df[['AEP_MW']].resample('Q').sum()[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93565548-acb3-483d-8ed4-79ca89d23a5a",
   "metadata": {},
   "source": [
    "# Time Series Analysis. Frequency:<a id='start'></a>\n",
    "[1. Quarterly.](#quarterly)<br>\n",
    "[2. Monthly.](#monthly)<br>\n",
    "[3. Weekly.](#weekly)<br>\n",
    "[4. Daily.](#daily)<br>\n",
    "[5. Hourly.](#hourly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab2f9a-b08f-4aea-b329-088ba35160ef",
   "metadata": {},
   "source": [
    "<a id='quarterly'></a>\n",
    "# Quarterly\n",
    "[Back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d63002c-e71c-4b80-90e7-f424301f64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Determining seasonality\n",
    "plot_acf(quarterly_df, lags=50)\n",
    "plt.figure(figsize = (30, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d89738-9474-4e4d-b0e9-e39c55e4d533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TimeSeries\n",
    "ts=quarterly_df.loc['2005':'2018'].copy()\n",
    "seasonality=4\n",
    "ts_train=ts.loc['2005':'2016'].copy()\n",
    "ts_test=ts.loc['2017':'2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='Q'\n",
    "maxiter=300\n",
    "period='quarterly'\n",
    "result = seasonal_decompose(ts_train, model='additive',extrapolate_trend='freq')\n",
    "d= calculate_d(ts_train)\n",
    "D=calculate_d(result.seasonal)\n",
    "\n",
    "print('This is my d: ',d)\n",
    "print('This is my D: ',D)\n",
    "outcome=calculate_p_q(ts_train,d,D,freq)\n",
    "\n",
    "pdq=outcome.loc[0,'pdq']\n",
    "pdqs=outcome.loc[0,'pdqs']\n",
    "\n",
    "                               \n",
    "#Build SARIMAX model w/optimal parameters\n",
    "sarimax = sm.tsa.statespace.SARIMAX(ts_train,\n",
    "                                    order=pdq,\n",
    "                                    seasonal_order=pdqs,\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False,\n",
    "                                    freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "output = sarimax.fit(disp=False,maxiter=maxiter,)\n",
    "pickle_model(pdq,pdqs,output,period)\n",
    "# Print output summary\n",
    "print(output.summary())\n",
    "# Plot diagnostics\n",
    "output.plot_diagnostics(figsize=(16,10));\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac21406-885f-42c1-817a-bcb55aabad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=quarterly_df.loc['2005':'2018'].copy()\n",
    "seasonality=4\n",
    "ts_train=ts.loc['2005':'2016'].copy()\n",
    "ts_test=ts.loc['2017':'2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='Q'\n",
    "maxiter=300\n",
    "period='quarterly'\n",
    "\n",
    "###Recovering parameters, if needed it\n",
    "file = open('best_parameters.pkl', 'rb')\n",
    "best_parameters = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "pdq=best_parameters[period][0]\n",
    "pdqs=best_parameters[period][1]\n",
    "model_q=best_parameters[period][2]\n",
    "\n",
    "\n",
    "forecast=model_q.get_forecast(steps=periods_to_test)\n",
    "ci=forecast.conf_int()\n",
    "predictions=forecast.predicted_mean\n",
    "ts_test['preds']=predictions\n",
    "\n",
    "sarimax_rmse=round(np.sqrt(mean_squared_error(ts_test.AEP_MW,predictions)),2)\n",
    "sarimax_nrmse=sarimax_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW))\n",
    "print(\"NRMSE: \",sarimax_nrmse,)\n",
    "\n",
    "printing_ci()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40fdb8f-a624-4016-8ea8-4188b36b2638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prophet\n",
    "ts=quarterly_df.loc['2005':'2018'].copy()\n",
    "seasonality=4\n",
    "ts_train=ts.loc['2005':'2016'].copy()\n",
    "ts_test=ts.loc['2017':'2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='Q'\n",
    "\n",
    "####Prepping for Prophet\n",
    "ts_train=ts_train.reset_index()\n",
    "\n",
    "ts_train.rename(columns={'AEP_MW':'y','Datetime':'ds'}, inplace = True)\n",
    "ts_train.y.plot()\n",
    "ts_train['y'] = np.log(ts_train['y'])\n",
    "model = Prophet()\n",
    "model.fit(ts_train,)\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "\n",
    "ts_test['preds']=predictions\n",
    "# ts_test[['AEP_MW','FBP_preds']].plot()\n",
    "prophet_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,ts_test.preds))\n",
    "prophet_nrmse=round(prophet_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",prophet_nrmse)\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09cd751-fd80-4fef-82ed-7f4dca217c1c",
   "metadata": {},
   "source": [
    "# And the winner is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b7c0b-d243-4b28-ad35-21550627de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if round(sarimax_nrmse-prophet_nrmse,2) >0:\n",
    "    print('Prophet WINS')\n",
    "elif round(sarimax_nrmse-prophet_nrmse,2) <0:\n",
    "    print('SARIMAX WINS')\n",
    "else:\n",
    "    print('It is a tie')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2b922-5b6b-4b45-b247-c4a90d900a08",
   "metadata": {},
   "source": [
    "<a id='monthly'></a>\n",
    "# Monthly Analysis\n",
    "[Back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c657760-1ce0-488e-b8fe-84703417caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Determining seasonality\n",
    "plot_acf(monthly_df, lags=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3187f9-298a-4eed-bfe1-d0e53a6694d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##TimeSeries\n",
    "ts=monthly_df.loc['2008':'2018'].copy()\n",
    "seasonality=12\n",
    "ts_train=ts.loc['2005':'2016'].copy()\n",
    "ts_test=ts.loc['2017':'2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='M'\n",
    "maxiter=100\n",
    "period='monthly'\n",
    "result = seasonal_decompose(ts_train, model='additive',extrapolate_trend='freq')\n",
    "d= calculate_d(ts_train)\n",
    "D=calculate_d(result.seasonal)\n",
    "\n",
    "print('This is my d: ',d)\n",
    "print('This is my D: ',D)\n",
    "outcome=calculate_p_q(ts_train,d,D,freq)\n",
    "\n",
    "pdq=outcome.loc[0,'pdq']\n",
    "pdqs=outcome.loc[0,'pdqs']\n",
    "\n",
    "                               \n",
    "#Build SARIMAX model w/optimal parameters\n",
    "sarimax = sm.tsa.statespace.SARIMAX(ts_train,\n",
    "                                    order=pdq,\n",
    "                                    seasonal_order=pdqs,\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False,\n",
    "                                    freq=freq)\n",
    "\n",
    "# Fit the model\n",
    "output = sarimax.fit(disp=False,maxiter=maxiter,)#method_kwargs={\"warn_convergence\": False}\n",
    "pickle_model(pdq,pdqs,output,period)\n",
    "# Print output summary\n",
    "print(output.summary())\n",
    "# Plot diagnostics\n",
    "output.plot_diagnostics(figsize=(16,10));\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01947a96-db5e-4c00-9c29-fbf80e6c4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=monthly_df.loc['2005':'2018'].copy()\n",
    "seasonality=12\n",
    "ts_train=ts.loc['2005':'2016'].copy()\n",
    "ts_test=ts.loc['2017':'2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='M'\n",
    "maxiter=100\n",
    "period='monthly'\n",
    "\n",
    "###Recovering parameters, if needed it\n",
    "file = open('best_parameters.pkl', 'rb')\n",
    "best_parameters = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "pdq=best_parameters[period][0]\n",
    "pdqs=best_parameters[period][1]\n",
    "model_m=best_parameters[period][2]\n",
    "\n",
    "forecast=model_m.get_forecast(steps=periods_to_test)\n",
    "ci=forecast.conf_int()\n",
    "predictions=forecast.predicted_mean\n",
    "ts_test['preds']=predictions\n",
    "sarimax_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,predictions))\n",
    "sarimax_nrmse= round(sarimax_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",sarimax_nrmse,)\n",
    "\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7badf56e-034b-400f-8f70-f6ded44e8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prophet\n",
    "ts=monthly_df.loc['2005':'2018'].copy()\n",
    "seasonality=12\n",
    "ts_train=ts.loc['2005':'2016'].copy()\n",
    "ts_test=ts.loc['2017':'2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='M'\n",
    "####Prepping for Prophet\n",
    "ts_train=ts_train.reset_index()\n",
    "ts_train\n",
    "\n",
    "ts_train.rename(columns={'AEP_MW':'y','Datetime':'ds'}, inplace = True)\n",
    "ts_train.y.plot()\n",
    "ts_train['y'] = np.log(ts_train['y'])\n",
    "model = Prophet()\n",
    "model.fit(ts_train)\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = 'M')\n",
    "forecast = model.predict(future)\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "\n",
    "\n",
    "ts_test['preds']=predictions\n",
    "# ts_test[['AEP_MW','FBP_preds']].plot()\n",
    "prophet_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,ts_test.preds))\n",
    "prophet_nrmse=round(prophet_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",prophet_nrmse)\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08001554-970c-428d-91b7-06d8bd34ae79",
   "metadata": {},
   "source": [
    "# And the winner is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca6401-595e-4410-b512-d96a6e421399",
   "metadata": {},
   "outputs": [],
   "source": [
    "if round(sarimax_rmse-prophet_rmse,2) >0:\n",
    "    print('Prophet WINS')\n",
    "elif round(sarimax_rmse-prophet_rmse,2) <0:\n",
    "    print('Sarimax WINS')\n",
    "else:\n",
    "    print('It is a tie')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ed870-01ba-4b61-9d28-6da1546acfd4",
   "metadata": {},
   "source": [
    "<a id='weekly'></a>\n",
    "# Weekly Analysis\n",
    "[Back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea562f22-221f-4bbd-8b82-1e22b11b3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Determining seasonality\n",
    "plot_acf(weekly_df.loc['2016':'2018'], lags=104)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b215f5-b2c3-4f15-bbdd-f9adca26b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=weekly_df.loc['2014':'2018'].copy()\n",
    "seasonality=26\n",
    "freq='W'\n",
    "\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "ts_train=ts.loc['2014':'2017'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=200\n",
    "period='weekly'\n",
    "result = seasonal_decompose(ts_train, model='additive',extrapolate_trend='freq')\n",
    "d= calculate_d(ts_train)\n",
    "D=calculate_d(result.seasonal)\n",
    "\n",
    "print('This is my d: ',d)\n",
    "print('This is my D: ',D)\n",
    "outcome=calculate_p_q(ts_train,d,D,freq)\n",
    "\n",
    "pdq=outcome.loc[0,'pdq']\n",
    "pdqs=outcome.loc[0,'pdqs']\n",
    "\n",
    "                               \n",
    "#Build SARIMAX model w/optimal parameters\n",
    "sarimax = sm.tsa.statespace.SARIMAX(ts_train,\n",
    "                                    order=pdq,\n",
    "                                    seasonal_order=pdqs,\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False,\n",
    "                                    freq=freq)\n",
    "# Fit the model\n",
    "output = sarimax.fit(disp=False,maxiter=maxiter,)#method_kwargs={\"warn_convergence\": False}\n",
    "pickle_model(pdq,pdqs,output,period)\n",
    "# Print output summary\n",
    "print(output.summary())\n",
    "# Plot diagnostics\n",
    "output.plot_diagnostics(figsize=(16,10));\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29495925-d76b-479d-8dd4-fe57d16e0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=s=weekly_df.loc['2015':'2018'].copy()\n",
    "seasonality=26\n",
    "freq='W'\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "ts_train=ts.loc['2015':'2017'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=300\n",
    "period='weekly'\n",
    "\n",
    "###Recovering parameters, if needed it\n",
    "file = open('best_parameters.pkl', 'rb')\n",
    "best_parameters = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "pdq=best_parameters[period][0]\n",
    "pdqs=best_parameters[period][1]\n",
    "model_w=best_parameters[period][2]\n",
    "\n",
    "forecast=model_w.get_forecast(steps=periods_to_test)\n",
    "ci=forecast.conf_int()\n",
    "predictions=forecast.predicted_mean\n",
    "ts_test['preds']=predictions\n",
    "sarimax_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,predictions))\n",
    "sarimax_nrmse= round(sarimax_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",sarimax_nrmse,)\n",
    "\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1b042c-9106-432f-a386-114845cad16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prophet\n",
    "ts=weekly_df.loc['2014':'2018'].copy()\n",
    "seasonality=26\n",
    "ts_train=ts.loc['2014':'2017'].copy()\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='W'\n",
    "####Prepping for Prophet\n",
    "ts_train=ts_train.reset_index()\n",
    "ts_train\n",
    "\n",
    "ts_train.rename(columns={'AEP_MW':'y','Datetime':'ds'}, inplace = True)\n",
    "ts_train.y.plot()\n",
    "ts_train['y'] = np.log(ts_train['y'])\n",
    "model = Prophet()\n",
    "model.fit(ts_train)\n",
    "####Prepping for Prophet\n",
    "ts_train=ts_train.reset_index()\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = 'M')\n",
    "forecast = model.predict(future)\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "# ts_test[['AEP_MW','FBP_preds']].plot()\n",
    "prophet_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,ts_test.preds))\n",
    "prophet_nrmse=round(prophet_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",prophet_nrmse)\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac7485-8da5-4ef9-9fc4-d1bd5e31c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if round(sarimax_nrmse-prophet_nrmse,2) <0:\n",
    "    print('Sarimax WINS')\n",
    "elif round(sarimax_nrmse-prophet_nrmse,2) >0:\n",
    "    print('Prophet WINS')\n",
    "else:\n",
    "    print('It is a tie')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5533d-3060-4c70-8de9-57b1a9d20e46",
   "metadata": {},
   "source": [
    "<a id='daily'></a>\n",
    "# Daily Analysis\n",
    "[Back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eba1e1-88e5-4cb1-9355-424411394c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Determining seasonality\n",
    "plot_acf(daily_df.loc['2016':'2018'], lags=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562a4a9-1e66-4afb-ade7-5835bebe3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=daily_df.loc['2015':'2018'].copy()\n",
    "seasonality=7\n",
    "freq='D'\n",
    "\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "ts_train=ts.loc['2015':'2017'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=200\n",
    "period='daily_medium'\n",
    "result = seasonal_decompose(ts_train, model='additive',extrapolate_trend='freq')\n",
    "d= calculate_d(ts_train)\n",
    "D=calculate_d(result.seasonal)\n",
    "\n",
    "print('This is my d: ',d)\n",
    "print('This is my D: ',D)\n",
    "outcome=calculate_p_q(ts_train,d,D,freq)\n",
    "\n",
    "pdq=outcome.loc[0,'pdq']\n",
    "pdqs=outcome.loc[0,'pdqs']\n",
    "\n",
    "                               \n",
    "#Build SARIMAX model w/optimal parameters\n",
    "sarimax = sm.tsa.statespace.SARIMAX(ts_train,\n",
    "                                    order=pdq,\n",
    "                                    seasonal_order=pdqs,\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False,\n",
    "                                    freq=freq)\n",
    "# Fit the model\n",
    "output = sarimax.fit(disp=False,maxiter=maxiter,)#method_kwargs={\"warn_convergence\": False}\n",
    "pickle_model(pdq,pdqs,output,period)\n",
    "# Print output summary\n",
    "print(output.summary())\n",
    "# Plot diagnostics\n",
    "output.plot_diagnostics(figsize=(16,10));\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab489b-a62f-41c8-aa1d-fe3924b79d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=daily_df[-300:].copy()\n",
    "seasonality=7\n",
    "freq='D'\n",
    "\n",
    "ts_test=ts[-60:].copy()\n",
    "ts_train=ts[:-60].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=200\n",
    "period='daily_short'\n",
    "result = seasonal_decompose(ts_train, model='additive',extrapolate_trend='freq')\n",
    "d= calculate_d(ts_train)\n",
    "D=calculate_d(result.seasonal)\n",
    "\n",
    "print('This is my d: ',d)\n",
    "print('This is my D: ',D)\n",
    "outcome=calculate_p_q(ts_train,d,D,freq)\n",
    "\n",
    "pdq=outcome.loc[0,'pdq']\n",
    "pdqs=outcome.loc[0,'pdqs']\n",
    "\n",
    "                               \n",
    "#Build SARIMAX model w/optimal parameters\n",
    "sarimax = sm.tsa.statespace.SARIMAX(ts_train,\n",
    "                                    order=pdq,\n",
    "                                    seasonal_order=pdqs,\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False,\n",
    "                                    freq=freq)\n",
    "# Fit the model\n",
    "output = sarimax.fit(disp=False,maxiter=maxiter,)#method_kwargs={\"warn_convergence\": False}\n",
    "pickle_model(pdq,pdqs,output,period)\n",
    "# Print output summary\n",
    "print(output.summary())\n",
    "# Plot diagnostics\n",
    "output.plot_diagnostics(figsize=(16,10));\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c137c-7689-4a50-af17-cc1eb8929c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=daily_df.loc['2012':'2018'].copy()\n",
    "seasonality=7\n",
    "freq='D'\n",
    "\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "ts_train=ts.loc['2012':'2017'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=100\n",
    "period='daily'\n",
    "result = seasonal_decompose(ts_train, model='additive',extrapolate_trend='freq')\n",
    "d= calculate_d(ts_train)\n",
    "D=calculate_d(result.seasonal)\n",
    "\n",
    "print('This is my d: ',d)\n",
    "print('This is my D: ',D)\n",
    "outcome=calculate_p_q(ts_train,d,D,freq)\n",
    "\n",
    "pdq=outcome.loc[0,'pdq']\n",
    "pdqs=outcome.loc[0,'pdqs']\n",
    "\n",
    "                               \n",
    "#Build SARIMAX model w/optimal parameters\n",
    "sarimax = sm.tsa.statespace.SARIMAX(ts_train,\n",
    "                                    order=pdq,\n",
    "                                    seasonal_order=pdqs,\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False,\n",
    "                                    freq=freq)\n",
    "# Fit the model\n",
    "output = sarimax.fit(disp=False,maxiter=maxiter,)#method_kwargs={\"warn_convergence\": False}\n",
    "pickle_model(pdq,pdqs,output,period)\n",
    "# Print output summary\n",
    "print(output.summary())\n",
    "# Plot diagnostics\n",
    "output.plot_diagnostics(figsize=(16,10));\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e639fb-ed51-4f79-a9d3-ed10fb0fe75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=daily_df.loc['2012':'2018'].copy()\n",
    "seasonality=7\n",
    "freq='D'\n",
    "\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "ts_train=ts.loc['2012':'2017'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=300\n",
    "\n",
    "period='daily_medium'\n",
    "\n",
    "###Recovering parameters, if needed it\n",
    "file = open('best_parameters.pkl', 'rb')\n",
    "best_parameters = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "pdq=best_parameters[period][0]\n",
    "pdqs=best_parameters[period][1]\n",
    "model_d=best_parameters[period][2]\n",
    "\n",
    "forecast=model_d.get_forecast(steps=periods_to_test)\n",
    "ci=forecast.conf_int()\n",
    "#predictions=forecast.predicted_mean\n",
    "ts_test['preds']=forecast.predicted_mean\n",
    "sarimax_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,predictions))\n",
    "sarimax_nrmse= round(sarimax_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",sarimax_nrmse,)\n",
    "\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f3ecc-ee3e-49b0-8975-2f5e3d2c8241",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_test.preds.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cb4c6-43eb-413c-b762-3dacdd39d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=daily_df[-300:].copy()\n",
    "seasonality=7\n",
    "freq='D'\n",
    "\n",
    "ts_test=ts[-60:].copy()\n",
    "ts_train=ts[:-60].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=300\n",
    "\n",
    "period='daily_short'\n",
    "\n",
    "###Recovering parameters, if needed it\n",
    "file = open('best_parameters.pkl', 'rb')\n",
    "best_parameters = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "pdq=best_parameters[period][0]\n",
    "pdqs=best_parameters[period][1]\n",
    "model_d=best_parameters[period][2]\n",
    "\n",
    "forecast=model_d.get_forecast(steps=periods_to_test)\n",
    "ci=forecast.conf_int()\n",
    "predictions=forecast.predicted_mean\n",
    "ts_test['preds']=forecast.predicted_mean\n",
    "sarimax_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,predictions))\n",
    "sarimax_nrmse= round(sarimax_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",sarimax_nrmse,)\n",
    "\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e920e7-8820-4ae8-a68e-d2a8439c92ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=daily_df.loc['2012':'2018'].copy()\n",
    "seasonality=7\n",
    "freq='D'\n",
    "\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "ts_train=ts.loc['2012':'2017'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=300\n",
    "\n",
    "period='daily'\n",
    "\n",
    "###Recovering parameters, if needed it\n",
    "file = open('best_parameters.pkl', 'rb')\n",
    "best_parameters = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "pdq=best_parameters[period][0]\n",
    "pdqs=best_parameters[period][1]\n",
    "model_d=best_parameters[period][2]\n",
    "\n",
    "forecast=model_d.get_forecast(steps=periods_to_test)\n",
    "ci=forecast.conf_int()\n",
    "predictions=forecast.predicted_mean\n",
    "ts_test['preds']=predictions\n",
    "sarimax_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,predictions))\n",
    "sarimax_nrmse= round(sarimax_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",sarimax_nrmse,)\n",
    "\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf335c4-f340-4e48-a07d-b96e40c19906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prophet\n",
    "ts=daily_df.loc['2012':'2018'].copy()\n",
    "seasonality=7\n",
    "ts_train=ts.loc['2012':'2017'].copy()\n",
    "ts_test=ts.loc['2018'].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "freq='D'\n",
    "####Prepping for Prophet\n",
    "ts_train=ts_train.reset_index()\n",
    "ts_train\n",
    "\n",
    "ts_train.rename(columns={'AEP_MW':'y','Datetime':'ds'}, inplace = True)\n",
    "ts_train.y.plot()\n",
    "ts_train['y'] = np.log(ts_train['y'])\n",
    "model = Prophet()\n",
    "model.fit(ts_train)\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = 'D')\n",
    "forecast = model.predict(future)\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "# ts_test[['AEP_MW','FBP_preds']].plot()\n",
    "prophet_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,ts_test.preds))\n",
    "prophet_nrmse=round(prophet_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",prophet_nrmse)\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ec40f-cbf3-4021-8b65-b2ec86b87277",
   "metadata": {},
   "outputs": [],
   "source": [
    "if round(sarimax_rmse-prophet_rmse,2) <0:\n",
    "    print('Sarimax WINS')\n",
    "elif round(sarimax_rmse-prophet_rmse,2) >0:\n",
    "    print('Prophet WINS')\n",
    "else:\n",
    "    print('It is a tie')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2d6039-e0e5-40f3-a646-dd3bbd21adf3",
   "metadata": {},
   "source": [
    "<a id='hourly'></a>\n",
    "# Hourly Analysis\n",
    "[Back top](#start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad136aff-2134-4ca5-916e-a761e38490b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Determining seasonality\n",
    "plot_acf(hourly_df.loc['2016':'2018'], lags=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cac61e-fe89-4082-baa0-4a84a912aaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "ts=hourly_df[-600:].copy()\n",
    "seasonality=24\n",
    "freq='H'\n",
    "ts_test=ts[-72:].copy()\n",
    "ts_train=ts[:-72].copy()\n",
    "# ts_test=ts[-int(ts.shape[0]*0.2):].copy()\n",
    "# ts_train=ts[:-int(ts.shape[0]*0.2)].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "maxiter=200\n",
    "period='hourly'\n",
    "result = seasonal_decompose(ts_train, model='additive',extrapolate_trend='freq')\n",
    "d= calculate_d(ts_train)\n",
    "D=calculate_d(result.seasonal)\n",
    "\n",
    "print('This is my d: ',d)\n",
    "print('This is my D: ',D)\n",
    "outcome=calculate_p_q(ts_train,d,D,freq)\n",
    "\n",
    "pdq=outcome.loc[0,'pdq']\n",
    "pdqs=outcome.loc[0,'pdqs']\n",
    "\n",
    "                               \n",
    "#Build SARIMAX model w/optimal parameters\n",
    "sarimax = sm.tsa.statespace.SARIMAX(ts_train,\n",
    "                                    order=pdq,\n",
    "                                    seasonal_order=pdqs,\n",
    "                                    enforce_stationarity=False,\n",
    "                                    enforce_invertibility=False,\n",
    "                                    freq=freq)\n",
    "# Fit the model\n",
    "output = sarimax.fit(disp=False,maxiter=maxiter,)#method_kwargs={\"warn_convergence\": False}\n",
    "pickle_model(pdq,pdqs,output,period)\n",
    "# Print output summary\n",
    "print(output.summary())\n",
    "# Plot diagnostics\n",
    "output.plot_diagnostics(figsize=(16,10));\n",
    "url = \"https://www.youtube.com/watch?v=Udt-9J8nzGE\"\n",
    "webbrowser.open(url,new=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047a414e-4eae-47eb-be14-bb7dabc43730",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TimeSeries\n",
    "\n",
    "ts=hourly_df[-600:].copy()\n",
    "seasonality=24\n",
    "freq='H'\n",
    "ts_test=ts[-72:].copy()\n",
    "ts_train=ts[:-72].copy()\n",
    "periods_to_test=ts_test.shape[0]\n",
    "\n",
    "period='hourly'\n",
    "\n",
    "###Recovering parameters, if needed it\n",
    "file = open('best_parameters.pkl', 'rb')\n",
    "best_parameters = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()\n",
    "pdq=best_parameters[period][0]\n",
    "pdqs=best_parameters[period][1]\n",
    "model_h=best_parameters[period][2]\n",
    "\n",
    "forecast=model_h.get_forecast(steps=periods_to_test)\n",
    "ci=forecast.conf_int()\n",
    "predictions=forecast.predicted_mean\n",
    "ts_test['preds']=predictions\n",
    "sarimax_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,predictions))\n",
    "sarimax_nrmse= round(sarimax_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",sarimax_nrmse,)\n",
    "\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edf527-7adc-4202-83ce-343528b93d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prophet\n",
    "s=hourly_df[-600:].copy()\n",
    "seasonality=24\n",
    "freq='H'\n",
    "ts_test=ts[-72:].copy()\n",
    "ts_train=ts[:-72].copy()\n",
    "\n",
    "####Prepping for Prophet\n",
    "ts_train=ts_train.reset_index()\n",
    "ts_train\n",
    "\n",
    "ts_train.rename(columns={'AEP_MW':'y','Datetime':'ds'}, inplace = True)\n",
    "ts_train.y.plot()\n",
    "ts_train['y'] = np.log(ts_train['y'])\n",
    "model = Prophet()\n",
    "model.fit(ts_train)\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "future = model.make_future_dataframe(periods=periods_to_test, freq = freq)\n",
    "forecast = np.exp(model.predict(future)[-periods_to_test:].set_index('ds')[['yhat_lower','yhat_upper','yhat']])\n",
    "predictions=forecast.yhat\n",
    "ts_test['preds']=forecast.yhat\n",
    "ci=forecast[['yhat_lower','yhat_upper']]\n",
    "# ts_test[['AEP_MW','FBP_preds']].plot()\n",
    "prophet_rmse=np.sqrt(mean_squared_error(ts_test.AEP_MW,ts_test.preds))\n",
    "prophet_nrmse=round(prophet_rmse/(np.max(ts_test.AEP_MW)-np.min(ts_test.AEP_MW)),2)\n",
    "print(\"NRMSE: \",prophet_nrmse)\n",
    "printing_ci()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc955887-1a16-44fe-91f6-65cdd27c8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if round(sarimax_nrmse-prophet_nrmse,2) <0:\n",
    "    print('Sarimax WINS')\n",
    "elif round(sarimax_nrmse-prophet_nrmse,2) >0:\n",
    "    print('Prophet WINS')\n",
    "else:\n",
    "    print('It is a tie')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f9816-de41-4d2a-8df1-c0857104bf42",
   "metadata": {},
   "source": [
    "We did an analysis over a time series using SARIMA and FBProphet. In all these cases, using the **Normalized Root Mean Squared Error** as a metric, Prophet outscores SARIMA. We might try to dig a little deeper and add some other thoughts and ideas. We are taking about the **conclusions**. Before we do so, I want to prevent us to fall into Recency Bias (thinking that our last case is the one that matters), Confirmation bias (this is what I thought therefore this is it) or, in other words, extend the conclusions of this only case to all other situations and time series we can find in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d675f-a02d-4aa1-9423-91922bda206f",
   "metadata": {},
   "source": [
    "# **Conclusions**:\n",
    "\n",
    "1. SARIMA is way slower. It takes more time to train SARIMA and then run the winner. FBrophet has no parameters to tune\n",
    "2. Prophet scores lower (and better) nrmse most of the times. Sarimax is only better in weekly and hourly. It feels like sarimax does not gain from adding more data points to the dataset. After certain amount of rows, it does not get better rather it worsens\n",
    "3. SARIMA seems to pick up better the small nuances of the time series like we can see on the weekly analysis. Despite this, Prophet scored better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c57276-3684-4248-b77a-28baf773ccc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
